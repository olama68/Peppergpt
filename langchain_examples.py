# -*- coding: utf-8 -*-
"""Langchain_examples.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/mimendez00/mimendez_public_data/blob/main/Langchain_examples.ipynb
"""

import os
os.environ['OPENAI_API_KEY'] = ""
os.environ['COHERE_API_KEY'] = ""

# All of this was taken from https://langchain.readthedocs.io/en/latest/modules/document_loaders/examples/unstructured_file.html

## Install package
!pip install "unstructured[local-inference]"
!pip install "detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2"
!pip install layoutparser[layoutmodels,tesseract]
!pip install langchain
!pip install cohere
!pip install pysrt
!pip install openai
!pip install chromadb
import nltk
nltk.download('punkt')

!wget https://raw.githubusercontent.com/mimendez00/mimendez_public_data/main/Andrej-v3.txt

from langchain.document_loaders import TextLoader

loader = TextLoader("Andrej-v3.txt")
docs = loader.load()

from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter(
    # Set a really small chunk size, just to show.
    chunk_size = 1000,
    chunk_overlap  = 200,
    separator = "\n"
)

texts = text_splitter.split_documents(docs)

print(len(texts))
print(texts[0])

from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.embeddings.cohere import CohereEmbeddings
from langchain.vectorstores import Chroma
from langchain import OpenAI, VectorDBQA, Cohere
from langchain.chains import VectorDBQAWithSourcesChain
import json

embeddings = OpenAIEmbeddings()
docsearch = Chroma.from_documents(texts, embeddings, metadatas=[{"source": f"{i}-pl"} for i in range(len(texts))])

print(len(texts))
print(texts[0])

from langchain.chains.qa_with_sources import load_qa_with_sources_chain
qa_chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type="map_rerank", return_intermediate_steps=True)

qa = VectorDBQAWithSourcesChain(combine_documents_chain=qa_chain, vectorstore=docsearch, verbose=True)
#qa = VectorDBQAWithSourcesChain.from_chain_type(OpenAI(temperature=0), chain_type="refine", vectorstore=docsearch, verbose=True)

query_question = "Did Lex mention Optimus?"


docresults = docsearch.similarity_search(query_question)
for i in range(len(docresults)):
  print(docresults[i].page_content)

qa({"question": query_question}, return_only_outputs=True)